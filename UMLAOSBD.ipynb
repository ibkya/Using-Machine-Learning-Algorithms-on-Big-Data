{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Session ve Veriseti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore')\n",
    "import findspark\n",
    "findspark.init('/Users/ibrahim/spark/spark-3.5.1-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/22 18:39:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.36:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Using ML Algorithms on Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Using ML Algorithms on Spark>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder  \n",
    "            .master(\"local\") \n",
    "            .appName(\"Using ML Algorithms on Spark\") \n",
    "            .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "sc\n",
    "# configin normalde boş bırakılması sisteme uygun bir şekilde configlenir. istersek ram ayarları gibi ayarları yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Names: string, Age: double, Total_Purchase: double, Account_Manager: int, Years: double, Num_Sites: double, Churn: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark.read.csv(\"./churn.csv\", header=True, inferSchema=True, sep=\",\")\n",
    "spark_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 18:39:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Names, Age, Total_Purchase, Account_Manager, Years, Num_Sites, Churn\n",
      " Schema: _c0, Names, Age, Total_Purchase, Account_Manager, Years, Num_Sites, Churn\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/ibrahim/Desktop/workspace/Data%20Science%20Stats/Using-Machine-Learning-Algorithms-on-Big-Data/churn.csv\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|_c0|           names| age|total_purchase|account_manager|years|num_sites|churn|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|  1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|  2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|  3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|  4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bir sıkıntı çıkarmaması için sütun isimleri küçültüldü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumnRenamed(\"_c0\",\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|index|           names| age|total_purchase|account_manager|years|num_sites|churn|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n",
      "|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n",
      "|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n",
      "|    3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n",
      "|    4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n",
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"names\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|             names|count|\n",
      "+------------------+-----+\n",
      "|     Jennifer Wood|    2|\n",
      "|      Patrick Bell|    1|\n",
      "|  Patrick Robinson|    1|\n",
      "|     Chelsea Marsh|    1|\n",
      "|       John Barber|    1|\n",
      "|       Amber Evans|    1|\n",
      "|     David Compton|    1|\n",
      "| Mr. Jerome Dawson|    1|\n",
      "|        Lisa Davis|    1|\n",
      "|     Maria Stanley|    1|\n",
      "|Alexandra Phillips|    1|\n",
      "|     Nicholas Levy|    1|\n",
      "|    Richard Farmer|    1|\n",
      "|     Linda Hubbard|    1|\n",
      "|    Jesse Mitchell|    1|\n",
      "|    Brittany Green|    1|\n",
      "|  Timothy Johnston|    1|\n",
      "|   Charles Whitney|    1|\n",
      "|    Tony Schneider|    1|\n",
      "|  Stefanie Miranda|    1|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"names\").count().sort(\"count\",ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aynı isimde olan Jennifer Wood ismi bir çoklama mı yoksa ayrı ayrı insanlar mı sorusunun cevabını alalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|index|        names| age|total_purchase|account_manager|years|num_sites|churn|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|   22|Jennifer Wood|35.0|       9381.12|              1| 6.78|     11.0|    1|\n",
      "|  439|Jennifer Wood|48.0|      11585.16|              0| 4.61|      9.0|    0|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.filter(spark_df.names == \"Jennifer Wood\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çıktıdan da görüldüğü üzere ayrı ayrı aynı isime sahip insanlarmış."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|           names|count|\n",
      "+----------------+-----+\n",
      "|    Patrick Bell|    1|\n",
      "|Patrick Robinson|    1|\n",
      "|   Chelsea Marsh|    1|\n",
      "|     John Barber|    1|\n",
      "|     Amber Evans|    1|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\"names\").dropDuplicates().groupby(\"names\").count().sort(\"count\", ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yukarıda names sütunu bazında tekrar eden verileri sildik bunları grupladık ve isimlerin ne kadar tekrar ettiğini count ile yanına yazdırdık bunun yanında count'a göre sıraladık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        names|\n",
      "+-------------+\n",
      "|Jennifer Wood|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.where(spark_df.index == 439).select(\"names\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|index|        names| age|total_purchase|account_manager|years|num_sites|churn|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "|  439|Jennifer Wood|48.0|      11585.16|              0| 4.61|      9.0|    0|\n",
      "+-----+-------------+----+--------------+---------------+-----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.where(spark_df.index == 439).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorgunun çıktısını bir girdi olarak kullanabilmek adına collect() fonksiyonunu kullanabiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jen = spark_df.where(spark_df.index == 439).collect()[0][\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jennifer Wood'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keşifçi Veri Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/22 18:40:11 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|             index|        names|              age|   total_purchase|   account_manager|            years|         num_sites|              churn|\n",
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|               900|          900|              900|              900|               900|              900|               900|                900|\n",
      "|   mean|             449.5|         NULL|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|0.16666666666666666|\n",
      "| stddev|259.95191863111916|         NULL|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969| 0.3728852122772358|\n",
      "|    min|                 0|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|                  0|\n",
      "|    max|               899|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|                  1|\n",
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>900</td>\n",
       "      <td>41.81666666666667</td>\n",
       "      <td>6.127560416916251</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_purchase</th>\n",
       "      <td>900</td>\n",
       "      <td>10062.82403333334</td>\n",
       "      <td>2408.644531858096</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18026.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account_manager</th>\n",
       "      <td>900</td>\n",
       "      <td>0.4811111111111111</td>\n",
       "      <td>0.4999208935073339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>900</td>\n",
       "      <td>5.27315555555555</td>\n",
       "      <td>1.274449013194616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sites</th>\n",
       "      <td>900</td>\n",
       "      <td>8.587777777777777</td>\n",
       "      <td>1.7648355920350969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <td>900</td>\n",
       "      <td>0.16666666666666666</td>\n",
       "      <td>0.3728852122772358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                    1                   2      3  \\\n",
       "summary          count                 mean              stddev    min   \n",
       "age                900    41.81666666666667   6.127560416916251   22.0   \n",
       "total_purchase     900    10062.82403333334   2408.644531858096  100.0   \n",
       "account_manager    900   0.4811111111111111  0.4999208935073339      0   \n",
       "years              900     5.27315555555555   1.274449013194616    1.0   \n",
       "num_sites          900    8.587777777777777  1.7648355920350969    3.0   \n",
       "churn              900  0.16666666666666666  0.3728852122772358      0   \n",
       "\n",
       "                        4  \n",
       "summary               max  \n",
       "age                  65.0  \n",
       "total_purchase   18026.01  \n",
       "account_manager         1  \n",
       "years                9.15  \n",
       "num_sites            14.0  \n",
       "churn                   1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.select(\"age\",\"total_purchase\", \"account_manager\", \"years\",\"num_sites\",\"churn\").describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.filter(spark_df.age > 47).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|churn|count|\n",
      "+-----+-----+\n",
      "|    1|  150|\n",
      "|    0|  750|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"churn\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makine öğrenim modeli tek bir fonksiyondan ibarettir esas üzerinde durmamız gereken konu çaprazlamalardır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aşağıdaki çaprazlama incelendiğinde churn olup olmama durumunun satın alma ile çaprazlaması sonucu şu sonuca ulaşıyoruz demek ki churn olup olmama satın alma ile alakalı değil çünkü ortalamaları birbirine çok yakın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|churn|avg(total_purchase)|\n",
      "+-----+-------------------+\n",
      "|    1| 10192.179933333337|\n",
      "|    0| 10036.952853333332|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"churn\").agg({\"total_purchase\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|churn|        avg(years)|\n",
      "+-----+------------------+\n",
      "|    1|5.8835999999999995|\n",
      "|    0|5.1510666666666625|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupby(\"churn\").agg({\"years\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_data = spark_df.drop(\"index\",\"names\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
